{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_bucket(bucket):\n",
    "    client = boto3.client('s3')\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket)\n",
    "    \n",
    "    for page in page_iterator:\n",
    "        if page['KeyCount'] > 0:\n",
    "            for item in page['Contents']:\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "pathlist=[]\n",
    "#for i in iterate_bucket(bucket='millionsongproject'):\n",
    "for i in iterate_bucket(bucket='cosc502millionsong'):\n",
    "    if counter<200000:\n",
    "        if i['Key'].endswith('.h5') and not i['Key']=='millionsongsubset/MillionSongSubset/AdditionalFiles/subset_msd_summary_file.h5':\n",
    "            pathlist.append(i['Key'])\n",
    "            counter+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext()\n",
    "ss=SparkSession \\\n",
    ".builder \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rdd=sc.parallelize(pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " 'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5',\n",
       " 'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAADZ128F9348C2E.h5',\n",
       " 'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAEF128F4273421.h5',\n",
       " 'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAFD128F92F423A.h5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_iter=path_rdd.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(path_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sample_rate=sc.emptyRDD()\n",
    "artist_7digitalid=sc.emptyRDD()\n",
    "artist_familiarity=sc.emptyRDD()\n",
    "artist_hotttnesss=sc.emptyRDD()\n",
    "artist_id=sc.emptyRDD()\n",
    "artist_latitude=sc.emptyRDD()\n",
    "artist_location=sc.emptyRDD()\n",
    "artist_longitude=sc.emptyRDD()\n",
    "artist_mbid=sc.emptyRDD()\n",
    "artist_mbtags=sc.emptyRDD()\n",
    "artist_mbtags_count=sc.emptyRDD()\n",
    "artist_name=sc.emptyRDD()\n",
    "artist_playmeid=sc.emptyRDD()\n",
    "artist_terms=sc.emptyRDD()\n",
    "artist_terms_freq=sc.emptyRDD()\n",
    "artist_terms_weight=sc.emptyRDD()\n",
    "audio_md5=sc.emptyRDD()\n",
    "bars_confidence=sc.emptyRDD()\n",
    "bars_start=sc.emptyRDD()\n",
    "beats_confidence=sc.emptyRDD()\n",
    "beats_start=sc.emptyRDD()\n",
    "danceability=sc.emptyRDD()\n",
    "duration=sc.emptyRDD()\n",
    "end_of_fade_in=sc.emptyRDD()\n",
    "energy=sc.emptyRDD()\n",
    "key=sc.emptyRDD()\n",
    "key_confidence=sc.emptyRDD()\n",
    "loudness=sc.emptyRDD()\n",
    "mode=sc.emptyRDD()\n",
    "mode_confidence=sc.emptyRDD()\n",
    "release=sc.emptyRDD()\n",
    "release_7digitalid=sc.emptyRDD()\n",
    "sections_confidence=sc.emptyRDD()\n",
    "sections_start=sc.emptyRDD()\n",
    "segments_confidence=sc.emptyRDD()\n",
    "segments_loudness_max=sc.emptyRDD()\n",
    "segments_loudness_max_time=sc.emptyRDD()\n",
    "segments_loudness_start=sc.emptyRDD()\n",
    "segments_pitches=sc.emptyRDD()\n",
    "segments_start=sc.emptyRDD()\n",
    "segments_timbre=sc.emptyRDD()\n",
    "similar_artists=sc.emptyRDD()\n",
    "song_hotttnesss=sc.emptyRDD()\n",
    "song_id=sc.emptyRDD()\n",
    "start_of_fade_out=sc.emptyRDD()\n",
    "tatums_confidence=sc.emptyRDD()\n",
    "tatums_start=sc.emptyRDD()\n",
    "tempo=sc.emptyRDD()\n",
    "time_signature=sc.emptyRDD()\n",
    "time_signature_confidence=sc.emptyRDD()\n",
    "title=sc.emptyRDD()\n",
    "track_7digitalid=sc.emptyRDD()\n",
    "track_id=sc.emptyRDD()\n",
    "year=sc.emptyRDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rdd(feature_rdd, data):\n",
    "    data=data.tolist()\n",
    "    data=[data]\n",
    "    temp_rdd=sc.parallelize(data)\n",
    "    return feature_rdd.union(temp_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40181)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-8969d6cfa0de>\", line 52, in <module>\n",
      "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
      "  File \"<ipython-input-34-bfebd29c4a55>\", line 5, in append_rdd\n",
      "    return feature_rdd.union(temp_rdd)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 567, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2532, in _jrdd\n",
      "    self._jrdd_deserializer, profiler)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2435, in _wrap_function\n",
      "    return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1659, in __getattr__\n",
      "    raise Py4JError(message)\n",
      "py4j.protocol.Py4JError: PythonFunction does not exist in the JVM\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hadoop/miniconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "PythonFunction does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8969d6cfa0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0msegments_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_segments_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0msegments_timbre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments_timbre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_segments_timbre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msimilar_artists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_artists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_similar_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0msong_hotttnesss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_hotttnesss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_song_hotttnesss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msong_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_song_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-bfebd29c4a55>\u001b[0m in \u001b[0;36mappend_rdd\u001b[0;34m(feature_rdd, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp_rdd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_rdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mother_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx,\n\u001b[0m\u001b[1;32m    568\u001b[0m                       self.ctx.serializer)\n\u001b[1;32m    569\u001b[0m         if (self.partitioner == other.partitioner and\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2532\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2533\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2534\u001b[0m                                              self.preservesPartitioning, self.is_barrier)\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[0m\u001b[1;32m   2436\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m             message = compute_exception_message(\n\u001b[1;32m   1658\u001b[0m                 \"{0} does not exist in the JVM\".format(name), error_message)\n\u001b[0;32m-> 1659\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: PythonFunction does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "import h5py_getter\n",
    "s3 = s3fs.S3FileSystem()\n",
    "BUCKET='s3://cosc502millionsong/'\n",
    "for a in path_iter:\n",
    "    if a=='millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5':\n",
    "        continue\n",
    "    address=BUCKET+a\n",
    "    with h5py.File(s3.open(address, 'rb'), 'r', lib_version='latest') as f:\n",
    "        analysis_sample_rate=append_rdd(analysis_sample_rate, h5py_getter.get_analysis_sample_rate(f))\n",
    "        artist_7digitalid=append_rdd(artist_7digitalid, h5py_getter.get_artist_7digitalid(f))\n",
    "        artist_familiarity=append_rdd(artist_familiarity, h5py_getter.get_artist_familiarity(f))\n",
    "        artist_hotttnesss=append_rdd(artist_hotttnesss, h5py_getter.get_artist_hotttnesss(f))\n",
    "        artist_id=append_rdd(artist_id, h5py_getter.get_artist_id(f))\n",
    "        artist_latitude=append_rdd(artist_latitude, h5py_getter.get_artist_latitude(f))\n",
    "        artist_location=append_rdd(artist_location, h5py_getter.get_artist_location(f))\n",
    "        artist_longitude=append_rdd(artist_longitude, h5py_getter.get_artist_longitude(f))\n",
    "        artist_mbid=append_rdd(artist_mbid, h5py_getter.get_artist_mbid(f))\n",
    "        artist_mbtags=append_rdd(artist_mbtags, h5py_getter.get_artist_mbtags(f))\n",
    "        artist_mbtags_count=append_rdd(artist_mbtags_count, h5py_getter.get_artist_mbtags_count(f))\n",
    "        artist_name=append_rdd(artist_name, h5py_getter.get_artist_name(f))\n",
    "        artist_playmeid=append_rdd(artist_playmeid, h5py_getter.get_artist_playmeid(f))\n",
    "        artist_terms=append_rdd(artist_terms, h5py_getter.get_artist_terms(f))\n",
    "        artist_terms_freq=append_rdd(artist_terms_freq, h5py_getter.get_artist_terms_freq(f))\n",
    "        artist_terms_weight=append_rdd(artist_terms_weight, h5py_getter.get_artist_terms_weight(f))\n",
    "        audio_md5=append_rdd(audio_md5, h5py_getter.get_audio_md5(f))\n",
    "        bars_confidence=append_rdd(bars_confidence, h5py_getter.get_bars_confidence(f))\n",
    "        bars_start=append_rdd(bars_start, h5py_getter.get_bars_start(f))\n",
    "        beats_confidence=append_rdd(beats_confidence, h5py_getter.get_beats_confidence(f))\n",
    "        beats_start=append_rdd(beats_start, h5py_getter.get_beats_start(f))\n",
    "        danceability=append_rdd(danceability, h5py_getter.get_danceability(f))\n",
    "        duration=append_rdd(duration, h5py_getter.get_duration(f))\n",
    "        end_of_fade_in=append_rdd(end_of_fade_in, h5py_getter.get_end_of_fade_in(f))\n",
    "        energy=append_rdd(energy, h5py_getter.get_energy(f))\n",
    "        key=append_rdd(key, h5py_getter.get_key(f))\n",
    "        key_confidence=append_rdd(key_confidence, h5py_getter.get_key_confidence(f))\n",
    "        loudness=append_rdd(loudness, h5py_getter.get_loudness(f))\n",
    "        mode=append_rdd(mode, h5py_getter.get_mode(f))\n",
    "        mode_confidence=append_rdd(mode_confidence, h5py_getter.get_mode_confidence(f))\n",
    "        release=append_rdd(release, h5py_getter.get_release(f))\n",
    "        release_7digitalid=append_rdd(release_7digitalid, h5py_getter.get_release_7digitalid(f))\n",
    "        sections_confidence=append_rdd(sections_confidence, h5py_getter.get_sections_confidence(f))\n",
    "        sections_start=append_rdd(sections_start, h5py_getter.get_sections_start(f))\n",
    "        segments_confidence=append_rdd(segments_confidence, h5py_getter.get_segments_confidence(f))\n",
    "        segments_loudness_max=append_rdd(segments_loudness_max, h5py_getter.get_segments_loudness_max(f))\n",
    "        segments_loudness_max_time=append_rdd(segments_loudness_max_time, h5py_getter.get_segments_loudness_max_time(f))\n",
    "        segments_loudness_start=append_rdd(segments_loudness_start, h5py_getter.get_segments_loudness_start(f))\n",
    "        segments_pitches=append_rdd(segments_pitches, h5py_getter.get_segments_pitches(f))\n",
    "        segments_start=append_rdd(segments_start, h5py_getter.get_segments_start(f))\n",
    "        segments_timbre=append_rdd(segments_timbre, h5py_getter.get_segments_timbre(f))\n",
    "        similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
    "        song_hotttnesss=append_rdd(song_hotttnesss, h5py_getter.get_song_hotttnesss(f))\n",
    "        song_id=append_rdd(song_id, h5py_getter.get_song_id(f))\n",
    "        start_of_fade_out=append_rdd(start_of_fade_out, h5py_getter.get_start_of_fade_out(f))\n",
    "        tatums_confidence=append_rdd(tatums_confidence, h5py_getter.get_tatums_confidence(f))\n",
    "        tatums_start=append_rdd(tatums_start, h5py_getter.get_tatums_start(f))\n",
    "        tempo=append_rdd(tempo, h5py_getter.get_tempo(f))\n",
    "        time_signature=append_rdd(time_signature, h5py_getter.get_time_signature(f))\n",
    "        time_signature_confidence=append_rdd(time_signature_confidence, h5py_getter.get_time_signature_confidence(f))\n",
    "        title=append_rdd(title, h5py_getter.get_title(f))\n",
    "        track_7digitalid=append_rdd(track_7digitalid, h5py_getter.get_track_7digitalid(f))\n",
    "        track_id=append_rdd(track_id, h5py_getter.get_track_id(f))\n",
    "        year=append_rdd(year, h5py_getter.get_year(f))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not supported type: <class 'bytes'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row, names)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not infer schema for type: <class 'bytes'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fa2a284d23ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtempdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;31m#df=df.withColumn(attribute, lit(None)).select(df.columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m#for c in df.columns:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msamplingRatio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row, names)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not supported type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not supported type: <class 'bytes'>"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "import h5py_getter\n",
    "from pyspark.sql import Row\n",
    "s3 = s3fs.S3FileSystem()\n",
    "address='s3://cosc502millionsong/millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'\n",
    "attributes = ['artist_7digitalid','artist_familiarity','artist_hotttnesss','artist_id',\n",
    "     'artist_latitude','artist_location','artist_longitude','artist_mbidartist_mbtags',\n",
    "     'artist_mbtags_count','artist_name','artist_playmeid','artist_terms',\n",
    "     'artist_terms_freq','artist_terms_weight','audio_md5', 'bars_confidence','bars_start',\n",
    "     'beats_confidence','beats_start','danceability','duration','end_of_fade_in',\n",
    "     'energy','key','key_confidence','loudness','mode','mode_confidence',\n",
    "     'release','release_7digitalid','sections_confidence','sections_start',\n",
    "     'segments_confidence','segments_loudness_max','segments_loudness_max_time',\n",
    "     'segments_loudness_start','segments_pitches','segments_start','segments_timbre',\n",
    "     'similar_artists','song_hotttnesss','song_id','start_of_fade_out','tatums_confidence',\n",
    "     'tatums_start','tempo','time_signature','time_signature_confidence','title','track_7digitalid',\n",
    "     'track_id','year']\n",
    "with h5py.File(s3.open(address, 'rb'), 'r', lib_version='latest') as f:\n",
    "    analysis_sample_rate=append_rdd(analysis_sample_rate, h5py_getter.get_analysis_sample_rate(f))\n",
    "    artist_7digitalid=append_rdd(artist_7digitalid, h5py_getter.get_artist_7digitalid(f))\n",
    "    artist_familiarity=append_rdd(artist_familiarity, h5py_getter.get_artist_familiarity(f))\n",
    "    artist_hotttnesss=append_rdd(artist_hotttnesss, h5py_getter.get_artist_hotttnesss(f))\n",
    "    artist_id=append_rdd(artist_id, h5py_getter.get_artist_id(f))\n",
    "    artist_latitude=append_rdd(artist_latitude, h5py_getter.get_artist_latitude(f))\n",
    "    artist_location=append_rdd(artist_location, h5py_getter.get_artist_location(f))\n",
    "    artist_longitude=append_rdd(artist_longitude, h5py_getter.get_artist_longitude(f))\n",
    "    artist_mbid=append_rdd(artist_mbid, h5py_getter.get_artist_mbid(f))\n",
    "    artist_mbtags=append_rdd(artist_mbtags, h5py_getter.get_artist_mbtags(f))\n",
    "    artist_mbtags_count=append_rdd(artist_mbtags_count, h5py_getter.get_artist_mbtags_count(f))\n",
    "    artist_name=append_rdd(artist_name, h5py_getter.get_artist_name(f))\n",
    "    artist_playmeid=append_rdd(artist_playmeid, h5py_getter.get_artist_playmeid(f))\n",
    "    artist_terms=append_rdd(artist_terms, h5py_getter.get_artist_terms(f))\n",
    "    artist_terms_freq=append_rdd(artist_terms_freq, h5py_getter.get_artist_terms_freq(f))\n",
    "    artist_terms_weight=append_rdd(artist_terms_weight, h5py_getter.get_artist_terms_weight(f))\n",
    "    audio_md5=append_rdd(audio_md5, h5py_getter.get_audio_md5(f))\n",
    "    bars_confidence=append_rdd(bars_confidence, h5py_getter.get_bars_confidence(f))\n",
    "    bars_start=append_rdd(bars_start, h5py_getter.get_bars_start(f))\n",
    "    beats_confidence=append_rdd(beats_confidence, h5py_getter.get_beats_confidence(f))\n",
    "    beats_start=append_rdd(beats_start, h5py_getter.get_beats_start(f))\n",
    "    danceability=append_rdd(danceability, h5py_getter.get_danceability(f))\n",
    "    duration=append_rdd(duration, h5py_getter.get_duration(f))\n",
    "    end_of_fade_in=append_rdd(end_of_fade_in, h5py_getter.get_end_of_fade_in(f))\n",
    "    energy=append_rdd(energy, h5py_getter.get_energy(f))\n",
    "    key=append_rdd(key, h5py_getter.get_key(f))\n",
    "    key_confidence=append_rdd(key_confidence, h5py_getter.get_key_confidence(f))\n",
    "    loudness=append_rdd(loudness, h5py_getter.get_loudness(f))\n",
    "    mode=append_rdd(mode, h5py_getter.get_mode(f))\n",
    "    mode_confidence=append_rdd(mode_confidence, h5py_getter.get_mode_confidence(f))\n",
    "    release=append_rdd(release, h5py_getter.get_release(f))\n",
    "    release_7digitalid=append_rdd(release_7digitalid, h5py_getter.get_release_7digitalid(f))\n",
    "    sections_confidence=append_rdd(sections_confidence, h5py_getter.get_sections_confidence(f))\n",
    "    sections_start=append_rdd(sections_start, h5py_getter.get_sections_start(f))\n",
    "    segments_confidence=append_rdd(segments_confidence, h5py_getter.get_segments_confidence(f))\n",
    "    segments_loudness_max=append_rdd(segments_loudness_max, h5py_getter.get_segments_loudness_max(f))\n",
    "    segments_loudness_max_time=append_rdd(segments_loudness_max_time, h5py_getter.get_segments_loudness_max_time(f))\n",
    "    segments_loudness_start=append_rdd(segments_loudness_start, h5py_getter.get_segments_loudness_start(f))\n",
    "    segments_pitches=append_rdd(segments_pitches, h5py_getter.get_segments_pitches(f))\n",
    "    segments_start=append_rdd(segments_start, h5py_getter.get_segments_start(f))\n",
    "    segments_timbre=append_rdd(segments_timbre, h5py_getter.get_segments_timbre(f))\n",
    "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
    "    song_hotttnesss=append_rdd(song_hotttnesss, h5py_getter.get_song_hotttnesss(f))\n",
    "    song_id=append_rdd(song_id, h5py_getter.get_song_id(f))\n",
    "    start_of_fade_out=append_rdd(start_of_fade_out, h5py_getter.get_start_of_fade_out(f))\n",
    "    tatums_confidence=append_rdd(tatums_confidence, h5py_getter.get_tatums_confidence(f))\n",
    "    tatums_start=append_rdd(tatums_start, h5py_getter.get_tatums_start(f))\n",
    "    tempo=append_rdd(tempo, h5py_getter.get_tempo(f))\n",
    "    time_signature=append_rdd(time_signature, h5py_getter.get_time_signature(f))\n",
    "    time_signature_confidence=append_rdd(time_signature_confidence, h5py_getter.get_time_signature_confidence(f))\n",
    "    title=append_rdd(title, h5py_getter.get_title(f))\n",
    "    track_7digitalid=append_rdd(track_7digitalid, h5py_getter.get_track_7digitalid(f))\n",
    "    track_id=append_rdd(track_id, h5py_getter.get_track_id(f))\n",
    "    year=append_rdd(year, h5py_getter.get_year(f))\n",
    "errors=0\n",
    "\n",
    "row=Row('analysis_sample_rate')\n",
    "df = analysis_sample_rate.map(row).toDF()\n",
    "for attribute in attributes:\n",
    "    row=Row(attribute)\n",
    "    tempdf = globals()[attribute].map(row).toDF()\n",
    "    #df=df.withColumn(attribute, lit(None)).select(df.columns)\n",
    "    #for c in df.columns:\n",
    "        #tempdf=tempdf.withColumn(c, lit(None)).select(tempdf.columns)\n",
    "    df=df.union(tempdf)\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|analysis_sample_rate|\n",
      "+--------------------+\n",
      "|               22050|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDD' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5b6896dbd8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0martist_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist_terms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0martist_terms_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist_terms_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0martist_terms_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist_terms_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msimilar_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similar_artists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RDD' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem()\n",
    "BUCKET='s3://cosc502millionsong/'\n",
    "for a in path_iter:\n",
    "    if a=='millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5':\n",
    "        continue\n",
    "    address=BUCKET+a\n",
    "    with h5py.File(s3.open(address, 'rb'), 'r', lib_version='latest') as f:\n",
    "        \"\"\"\n",
    "        metadata: artist_terms, 'artist_terms_freq', 'artist_terms_weight', 'similar_artists', 'songs'\n",
    "        \"\"\"\n",
    "        data=f['metadata']\n",
    "        artist_terms=append_rdd(artist_terms, data['artist_terms'][:])\n",
    "        artist_terms_freq.append(data['artist_terms_freq'][:])\n",
    "        artist_terms_weight.append(data['artist_terms_weight'][:])\n",
    "        similar_artists.append(data['similar_artists'][:])\n",
    "        songs.append(data['songs'][:])\n",
    "        \"\"\"\n",
    "        analysis: 'bars_confidence', 'bars_start', 'beats_confidence', \n",
    "        'beats_start', 'sections_confidence', 'sections_start', \n",
    "        'segments_confidence', 'segments_loudness_max', 'segments_loudness_max_time',\n",
    "        'segments_loudness_start', 'segments_pitches', 'segments_start', \n",
    "        'segments_timbre', 'songs', 'tatums_confidence', 'tatums_start'\n",
    "        \"\"\"\n",
    "        data=f['analysis']\n",
    "        bars_confidence.append(data['bars_confidence'][:])\n",
    "        bars_start.append(data['bars_start'][:])\n",
    "        beats_confidence.append(data['beats_confidence'][:])\n",
    "        beats_start.append(data['beats_start'][:])\n",
    "        analysis_songs.append(data['songs'][:])\n",
    "        sections_confidence.append(data['sections_confidence'][:])\n",
    "        sections_start.append(data['sections_start'][:])\n",
    "        segments_confidence.append(data['segments_confidence'][:])\n",
    "        segments_loudness_max.append(data['segments_loudness_max'][:])\n",
    "        segments_loudness_max_time.append(data['segments_loudness_max_time'][:])\n",
    "        segments_loudness_start.append(data['segments_loudness_start'][:])\n",
    "        segments_pitches.append(data['segments_pitches'][:])\n",
    "        segments_start.append(data['segments_start'][:])\n",
    "        segments_timbre.append(data['segments_timbre'][:])\n",
    "        tatums_confidence.append(data['tatums_confidence'][:])\n",
    "        tatums_start.append(data['tatums_start'][:])\n",
    "        \"\"\"\n",
    "        musicbrainz: 'artist_mbtags', 'artist_mbtags_count', 'songs'\n",
    "        \"\"\"\n",
    "        data=f['musicbrainz']\n",
    "        artist_mbtags.append(data['artist_mbtags'][:])\n",
    "        artist_mbtags_count.append(data['artist_mbtags_count'][:])\n",
    "        musicbrainz_songs.append(data['songs'][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(artist_terms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['artist_terms']=pd.Series(artist_terms)\n",
    "df['artist_terms_freq']=pd.Series(artist_terms_freq)\n",
    "df['artist_terms_weight']=pd.Series(artist_terms_weight)\n",
    "df['similar_artists']=pd.Series(similar_artists)\n",
    "df['songs']=pd.Series(songs)\n",
    "df['bars_confidence']=pd.Series(bars_confidence)\n",
    "df['bars_start']=pd.Series(bars_start)\n",
    "df['beats_confidence']=pd.Series(beats_confidence)\n",
    "df['beats_start']=pd.Series(beats_start)\n",
    "df['analysis_songs']=pd.Series(analysis_songs)\n",
    "df['sections_confidence']=pd.Series(sections_confidence)\n",
    "df['sections_start']=pd.Series(sections_start)\n",
    "df['segments_confidence']=pd.Series(segments_confidence)\n",
    "df['segments_loudness_max']=pd.Series(segments_loudness_max)\n",
    "df['segments_loudness_max_time']=pd.Series(segments_loudness_max_time)\n",
    "df['segments_loudness_start']=pd.Series(segments_loudness_start)\n",
    "df['segments_pitches']=pd.Series(segments_pitches)\n",
    "df['segments_start']=pd.Series(segments_start)\n",
    "df['segments_timbre']=pd.Series(segments_timbre)\n",
    "df['tatums_confidence']=pd.Series(tatums_confidence)\n",
    "df['tatums_start']=pd.Series(tatums_start)\n",
    "df['artist_mbtags']=pd.Series(artist_mbtags)\n",
    "df['artist_mbtags_count']=pd.Series(artist_mbtags_count)\n",
    "df['musicbrainz_songs']=pd.Series(musicbrainz_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_terms</th>\n",
       "      <th>artist_terms_freq</th>\n",
       "      <th>artist_terms_weight</th>\n",
       "      <th>similar_artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>bars_confidence</th>\n",
       "      <th>bars_start</th>\n",
       "      <th>beats_confidence</th>\n",
       "      <th>beats_start</th>\n",
       "      <th>analysis_songs</th>\n",
       "      <th>...</th>\n",
       "      <th>segments_loudness_max_time</th>\n",
       "      <th>segments_loudness_start</th>\n",
       "      <th>segments_pitches</th>\n",
       "      <th>segments_start</th>\n",
       "      <th>segments_timbre</th>\n",
       "      <th>tatums_confidence</th>\n",
       "      <th>tatums_start</th>\n",
       "      <th>artist_mbtags</th>\n",
       "      <th>artist_mbtags_count</th>\n",
       "      <th>musicbrainz_songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[b'salsa', b'cumbia', b'tejano', b'ranchera', ...</td>\n",
       "      <td>[1.0, 0.9422390717941641, 0.9422390717941641, ...</td>\n",
       "      <td>[1.0, 0.9582578450180738, 0.9582578450180738, ...</td>\n",
       "      <td>[b'ARFSJUG11C8A421AAD', b'AR8SD041187FB36015',...</td>\n",
       "      <td>[[b'', 290021, 0.4873567909281477, 0.343428378...</td>\n",
       "      <td>[0.98, 0.399, 0.185, 0.27, 0.422, 0.0, 0.445, ...</td>\n",
       "      <td>[0.73152, 1.39732, 2.04852, 2.68691, 3.315, 3....</td>\n",
       "      <td>[0.98, 0.399, 0.185, 0.27, 0.422, 0.0, 0.445, ...</td>\n",
       "      <td>[0.73152, 1.39732, 2.04852, 2.68691, 3.315, 3....</td>\n",
       "      <td>[[22050, b'fa329738005ca53715d9f7381a0d1fe3', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27572, 0.1589, 0.0515, 0.0741, 0.09185, 0.0...</td>\n",
       "      <td>[-60.0, -59.9, -12.744, -12.003, -12.991, -15....</td>\n",
       "      <td>[[1.0, 0.911, 0.18, 0.334, 0.327, 0.344, 0.302...</td>\n",
       "      <td>[0.0, 0.28154, 0.48395, 0.6937, 0.97859, 1.361...</td>\n",
       "      <td>[[0.0, 171.124, 9.459, -28.489, 57.482, -50.06...</td>\n",
       "      <td>[0.482, 0.676, 0.627, 0.549, 0.279, 0.264, 0.2...</td>\n",
       "      <td>[0.42132, 0.73152, 1.06609, 1.39732, 1.72854, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[b'pop rock', b'new wave', b'dance rock', b'ro...</td>\n",
       "      <td>[0.9885838625154639, 0.9672504640243684, 0.820...</td>\n",
       "      <td>[1.0, 0.9636972066614938, 0.9267729972686404, ...</td>\n",
       "      <td>[b'AR4R0741187FB39AF2', b'AR0D7K21187B9AD14E',...</td>\n",
       "      <td>[[b'', 19072, 0.6303823341467806, 0.4542311565...</td>\n",
       "      <td>[0.017, 0.05, 0.014, 0.008, 0.114, 0.019, 0.08...</td>\n",
       "      <td>[1.30621, 3.29887, 5.30252, 7.32327, 9.33775, ...</td>\n",
       "      <td>[0.809, 0.616, 0.789, 0.66, 0.439, 0.758, 0.60...</td>\n",
       "      <td>[0.81002, 1.30621, 1.80617, 2.2996, 2.80049, 3...</td>\n",
       "      <td>[[22050, b'43cd1abd45d5a2dda16a3c65b4963bd4', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.34385, 0.07741, 0.04658, 0.07981, 0.04477, ...</td>\n",
       "      <td>[-60.0, -27.665, -21.241, -15.222, -18.915, -1...</td>\n",
       "      <td>[[0.651, 0.592, 0.647, 0.494, 0.683, 0.919, 1....</td>\n",
       "      <td>[0.0, 0.70517, 1.03052, 1.21052, 1.52404, 1.72...</td>\n",
       "      <td>[[24.937, 37.465, 177.22, -216.443, 56.3, 202....</td>\n",
       "      <td>[0.601, 0.556, 0.523, 0.49, 0.466, 0.44, 0.428...</td>\n",
       "      <td>[0.56254, 0.81002, 1.05749, 1.30621, 1.55494, ...</td>\n",
       "      <td>[b'uk', b'british', b'english']</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[[0, 1982]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[b'pop punk', b'ska punk', b'breakcore', b'alt...</td>\n",
       "      <td>[0.8872883012773332, 0.7902037283563664, 0.790...</td>\n",
       "      <td>[1.0, 0.9609057433767874, 0.9592366232787087, ...</td>\n",
       "      <td>[b'ARUA62A1187B99D9B0', b'ARHJFFY1187B98BA76',...</td>\n",
       "      <td>[[b'', 30973, 0.6510456608317947, 0.4017236855...</td>\n",
       "      <td>[0.175, 0.409, 0.639, 0.067, 0.016, 0.066, 0.0...</td>\n",
       "      <td>[1.06368, 2.91491, 4.76729, 6.61852, 8.46978, ...</td>\n",
       "      <td>[0.883, 0.738, 0.484, 0.609, 0.625, 0.719, 0.4...</td>\n",
       "      <td>[0.13576, 0.59914, 1.06368, 1.52591, 1.99045, ...</td>\n",
       "      <td>[[22050, b'580a8fe08ef0f1c7734b84547d7a8bc7', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.06094, 0.06433, 0.02255, 0.02018, 0.02463, ...</td>\n",
       "      <td>[-60.0, -59.828, -19.551, -32.609, -21.899, -2...</td>\n",
       "      <td>[[1.0, 0.529, 0.407, 0.423, 0.524, 0.509, 0.65...</td>\n",
       "      <td>[0.0, 0.06603, 0.24395, 0.57034, 0.92567, 1.26...</td>\n",
       "      <td>[[0.089, 169.621, 5.435, -30.061, 54.144, -50....</td>\n",
       "      <td>[1.0, 0.98, 0.932, 0.87, 0.82, 0.793, 0.768, 0...</td>\n",
       "      <td>[0.13576, 0.36918, 0.59914, 0.83141, 1.06368, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 2007]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[b'southern gospel', b'bluegrass', b'gospel', ...</td>\n",
       "      <td>[1.0, 0.8776784423307522, 0.5756383007306756, ...</td>\n",
       "      <td>[1.0, 0.889349058121347, 0.660827892217304, 0....</td>\n",
       "      <td>[b'ARHNMEZ11F50C4706C', b'ARCAWRI1187B98CDA6',...</td>\n",
       "      <td>[[b'', 432935, 0.5352927355118197, 0.385470550...</td>\n",
       "      <td>[0.121, 0.511, 0.356, 0.397, 0.193, 0.262, 0.3...</td>\n",
       "      <td>[1.17118, 2.44699, 3.76552, 5.07403, 6.38454, ...</td>\n",
       "      <td>[0.438, 0.164, 0.143, 0.044, 0.047, 0.22, 0.27...</td>\n",
       "      <td>[0.74856, 1.17118, 1.59278, 2.0154, 2.44699, 2...</td>\n",
       "      <td>[[22050, b'8ee90e90bb8714300574486f379effb5', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.43155, 0.15939, 0.13164, 0.08969, 0.11711, ...</td>\n",
       "      <td>[-60.0, -58.929, -54.569, -48.97, -46.964, -45...</td>\n",
       "      <td>[[0.778, 0.152, 0.101, 0.119, 0.145, 1.0, 0.14...</td>\n",
       "      <td>[0.0, 0.44975, 0.62413, 1.06567, 1.27497, 1.54...</td>\n",
       "      <td>[[0.047, 170.004, 9.863, -29.763, 58.312, -50....</td>\n",
       "      <td>[0.136, 0.127, 0.113, 0.112, 0.104, 0.09, 0.07...</td>\n",
       "      <td>[0.53929, 0.74856, 0.95987, 1.17118, 1.38249, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[b'breakbeat', b'dirty south rap', b'hip hop',...</td>\n",
       "      <td>[1.0, 0.8386187613378114, 0.9353130749575775, ...</td>\n",
       "      <td>[1.0, 0.9258286857243918, 0.8650794411328923, ...</td>\n",
       "      <td>[b'ARF93II1187B99F981', b'ART6ONC11C8A421DB9',...</td>\n",
       "      <td>[[b'', 17970, 0.5564956019129572, 0.2619411773...</td>\n",
       "      <td>[0.709, 0.641, 0.531, 0.542, 0.47, 0.049, 0.57...</td>\n",
       "      <td>[0.27253, 0.70535, 1.13191, 1.53913, 1.94418, ...</td>\n",
       "      <td>[0.709, 0.641, 0.531, 0.542, 0.47, 0.049, 0.57...</td>\n",
       "      <td>[0.27253, 0.70535, 1.13191, 1.53913, 1.94418, ...</td>\n",
       "      <td>[[22050, b'0e574964bf7a546a39e039f6e35aa48a', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.07564, 0.05985, 0.03653, 0.07117, 0.07724, ...</td>\n",
       "      <td>[-60.0, -55.786, -55.547, -45.022, -19.357, -3...</td>\n",
       "      <td>[[1.0, 0.869, 0.687, 0.644, 0.774, 0.795, 0.8,...</td>\n",
       "      <td>[0.0, 0.09578, 0.45274, 0.64218, 0.76957, 1.06...</td>\n",
       "      <td>[[2.711, 176.591, 16.855, -58.658, 27.583, -26...</td>\n",
       "      <td>[0.467, 0.474, 0.528, 0.541, 0.507, 0.482, 0.3...</td>\n",
       "      <td>[0.05611, 0.27253, 0.48785, 0.70535, 0.92722, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        artist_terms  \\\n",
       "0  [b'salsa', b'cumbia', b'tejano', b'ranchera', ...   \n",
       "1  [b'pop rock', b'new wave', b'dance rock', b'ro...   \n",
       "2  [b'pop punk', b'ska punk', b'breakcore', b'alt...   \n",
       "3  [b'southern gospel', b'bluegrass', b'gospel', ...   \n",
       "4  [b'breakbeat', b'dirty south rap', b'hip hop',...   \n",
       "\n",
       "                                   artist_terms_freq  \\\n",
       "0  [1.0, 0.9422390717941641, 0.9422390717941641, ...   \n",
       "1  [0.9885838625154639, 0.9672504640243684, 0.820...   \n",
       "2  [0.8872883012773332, 0.7902037283563664, 0.790...   \n",
       "3  [1.0, 0.8776784423307522, 0.5756383007306756, ...   \n",
       "4  [1.0, 0.8386187613378114, 0.9353130749575775, ...   \n",
       "\n",
       "                                 artist_terms_weight  \\\n",
       "0  [1.0, 0.9582578450180738, 0.9582578450180738, ...   \n",
       "1  [1.0, 0.9636972066614938, 0.9267729972686404, ...   \n",
       "2  [1.0, 0.9609057433767874, 0.9592366232787087, ...   \n",
       "3  [1.0, 0.889349058121347, 0.660827892217304, 0....   \n",
       "4  [1.0, 0.9258286857243918, 0.8650794411328923, ...   \n",
       "\n",
       "                                     similar_artists  \\\n",
       "0  [b'ARFSJUG11C8A421AAD', b'AR8SD041187FB36015',...   \n",
       "1  [b'AR4R0741187FB39AF2', b'AR0D7K21187B9AD14E',...   \n",
       "2  [b'ARUA62A1187B99D9B0', b'ARHJFFY1187B98BA76',...   \n",
       "3  [b'ARHNMEZ11F50C4706C', b'ARCAWRI1187B98CDA6',...   \n",
       "4  [b'ARF93II1187B99F981', b'ART6ONC11C8A421DB9',...   \n",
       "\n",
       "                                               songs  \\\n",
       "0  [[b'', 290021, 0.4873567909281477, 0.343428378...   \n",
       "1  [[b'', 19072, 0.6303823341467806, 0.4542311565...   \n",
       "2  [[b'', 30973, 0.6510456608317947, 0.4017236855...   \n",
       "3  [[b'', 432935, 0.5352927355118197, 0.385470550...   \n",
       "4  [[b'', 17970, 0.5564956019129572, 0.2619411773...   \n",
       "\n",
       "                                     bars_confidence  \\\n",
       "0  [0.98, 0.399, 0.185, 0.27, 0.422, 0.0, 0.445, ...   \n",
       "1  [0.017, 0.05, 0.014, 0.008, 0.114, 0.019, 0.08...   \n",
       "2  [0.175, 0.409, 0.639, 0.067, 0.016, 0.066, 0.0...   \n",
       "3  [0.121, 0.511, 0.356, 0.397, 0.193, 0.262, 0.3...   \n",
       "4  [0.709, 0.641, 0.531, 0.542, 0.47, 0.049, 0.57...   \n",
       "\n",
       "                                          bars_start  \\\n",
       "0  [0.73152, 1.39732, 2.04852, 2.68691, 3.315, 3....   \n",
       "1  [1.30621, 3.29887, 5.30252, 7.32327, 9.33775, ...   \n",
       "2  [1.06368, 2.91491, 4.76729, 6.61852, 8.46978, ...   \n",
       "3  [1.17118, 2.44699, 3.76552, 5.07403, 6.38454, ...   \n",
       "4  [0.27253, 0.70535, 1.13191, 1.53913, 1.94418, ...   \n",
       "\n",
       "                                    beats_confidence  \\\n",
       "0  [0.98, 0.399, 0.185, 0.27, 0.422, 0.0, 0.445, ...   \n",
       "1  [0.809, 0.616, 0.789, 0.66, 0.439, 0.758, 0.60...   \n",
       "2  [0.883, 0.738, 0.484, 0.609, 0.625, 0.719, 0.4...   \n",
       "3  [0.438, 0.164, 0.143, 0.044, 0.047, 0.22, 0.27...   \n",
       "4  [0.709, 0.641, 0.531, 0.542, 0.47, 0.049, 0.57...   \n",
       "\n",
       "                                         beats_start  \\\n",
       "0  [0.73152, 1.39732, 2.04852, 2.68691, 3.315, 3....   \n",
       "1  [0.81002, 1.30621, 1.80617, 2.2996, 2.80049, 3...   \n",
       "2  [0.13576, 0.59914, 1.06368, 1.52591, 1.99045, ...   \n",
       "3  [0.74856, 1.17118, 1.59278, 2.0154, 2.44699, 2...   \n",
       "4  [0.27253, 0.70535, 1.13191, 1.53913, 1.94418, ...   \n",
       "\n",
       "                                      analysis_songs  ...  \\\n",
       "0  [[22050, b'fa329738005ca53715d9f7381a0d1fe3', ...  ...   \n",
       "1  [[22050, b'43cd1abd45d5a2dda16a3c65b4963bd4', ...  ...   \n",
       "2  [[22050, b'580a8fe08ef0f1c7734b84547d7a8bc7', ...  ...   \n",
       "3  [[22050, b'8ee90e90bb8714300574486f379effb5', ...  ...   \n",
       "4  [[22050, b'0e574964bf7a546a39e039f6e35aa48a', ...  ...   \n",
       "\n",
       "                          segments_loudness_max_time  \\\n",
       "0  [0.27572, 0.1589, 0.0515, 0.0741, 0.09185, 0.0...   \n",
       "1  [0.34385, 0.07741, 0.04658, 0.07981, 0.04477, ...   \n",
       "2  [0.06094, 0.06433, 0.02255, 0.02018, 0.02463, ...   \n",
       "3  [0.43155, 0.15939, 0.13164, 0.08969, 0.11711, ...   \n",
       "4  [0.07564, 0.05985, 0.03653, 0.07117, 0.07724, ...   \n",
       "\n",
       "                             segments_loudness_start  \\\n",
       "0  [-60.0, -59.9, -12.744, -12.003, -12.991, -15....   \n",
       "1  [-60.0, -27.665, -21.241, -15.222, -18.915, -1...   \n",
       "2  [-60.0, -59.828, -19.551, -32.609, -21.899, -2...   \n",
       "3  [-60.0, -58.929, -54.569, -48.97, -46.964, -45...   \n",
       "4  [-60.0, -55.786, -55.547, -45.022, -19.357, -3...   \n",
       "\n",
       "                                    segments_pitches  \\\n",
       "0  [[1.0, 0.911, 0.18, 0.334, 0.327, 0.344, 0.302...   \n",
       "1  [[0.651, 0.592, 0.647, 0.494, 0.683, 0.919, 1....   \n",
       "2  [[1.0, 0.529, 0.407, 0.423, 0.524, 0.509, 0.65...   \n",
       "3  [[0.778, 0.152, 0.101, 0.119, 0.145, 1.0, 0.14...   \n",
       "4  [[1.0, 0.869, 0.687, 0.644, 0.774, 0.795, 0.8,...   \n",
       "\n",
       "                                      segments_start  \\\n",
       "0  [0.0, 0.28154, 0.48395, 0.6937, 0.97859, 1.361...   \n",
       "1  [0.0, 0.70517, 1.03052, 1.21052, 1.52404, 1.72...   \n",
       "2  [0.0, 0.06603, 0.24395, 0.57034, 0.92567, 1.26...   \n",
       "3  [0.0, 0.44975, 0.62413, 1.06567, 1.27497, 1.54...   \n",
       "4  [0.0, 0.09578, 0.45274, 0.64218, 0.76957, 1.06...   \n",
       "\n",
       "                                     segments_timbre  \\\n",
       "0  [[0.0, 171.124, 9.459, -28.489, 57.482, -50.06...   \n",
       "1  [[24.937, 37.465, 177.22, -216.443, 56.3, 202....   \n",
       "2  [[0.089, 169.621, 5.435, -30.061, 54.144, -50....   \n",
       "3  [[0.047, 170.004, 9.863, -29.763, 58.312, -50....   \n",
       "4  [[2.711, 176.591, 16.855, -58.658, 27.583, -26...   \n",
       "\n",
       "                                   tatums_confidence  \\\n",
       "0  [0.482, 0.676, 0.627, 0.549, 0.279, 0.264, 0.2...   \n",
       "1  [0.601, 0.556, 0.523, 0.49, 0.466, 0.44, 0.428...   \n",
       "2  [1.0, 0.98, 0.932, 0.87, 0.82, 0.793, 0.768, 0...   \n",
       "3  [0.136, 0.127, 0.113, 0.112, 0.104, 0.09, 0.07...   \n",
       "4  [0.467, 0.474, 0.528, 0.541, 0.507, 0.482, 0.3...   \n",
       "\n",
       "                                        tatums_start  \\\n",
       "0  [0.42132, 0.73152, 1.06609, 1.39732, 1.72854, ...   \n",
       "1  [0.56254, 0.81002, 1.05749, 1.30621, 1.55494, ...   \n",
       "2  [0.13576, 0.36918, 0.59914, 0.83141, 1.06368, ...   \n",
       "3  [0.53929, 0.74856, 0.95987, 1.17118, 1.38249, ...   \n",
       "4  [0.05611, 0.27253, 0.48785, 0.70535, 0.92722, ...   \n",
       "\n",
       "                     artist_mbtags artist_mbtags_count musicbrainz_songs  \n",
       "0                               []                  []          [[0, 0]]  \n",
       "1  [b'uk', b'british', b'english']           [1, 1, 1]       [[0, 1982]]  \n",
       "2                               []                  []       [[0, 2007]]  \n",
       "3                               []                  []          [[0, 0]]  \n",
       "4                               []                  []          [[0, 0]]  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '19E1732382C52357',\n",
       "  'HostId': 'Pp2Bu/J4udlt3qdw549FM+BkkyRyADGiiILmkrYm5BJyeOjuQC9plwMrNLlzFyHlRJEg2b1f1Xg=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Pp2Bu/J4udlt3qdw549FM+BkkyRyADGiiILmkrYm5BJyeOjuQC9plwMrNLlzFyHlRJEg2b1f1Xg=',\n",
       "   'x-amz-request-id': '19E1732382C52357',\n",
       "   'date': 'Tue, 21 Apr 2020 18:00:34 GMT',\n",
       "   'etag': '\"49baac1a99e4f8c94f6868dfc29e61f6\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"49baac1a99e4f8c94f6868dfc29e61f6\"'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(\"cosc502millionsong\", 'subset_test.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_write = df.to_csv(None).encode()\n",
    "fs = s3fs.S3FileSystem()\n",
    "with fs.open('s3://cosc502millionsong/test_file.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('s3://cosc502millionsong/df_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'S3File' object has no attribute 'seek'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0a657f9af1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS3FileSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3://millionsongproject/A/A/A/TRAAAAV128F421A322.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'labtest'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfile_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/defs.pyx\u001b[0m in \u001b[0;36mh5py.defs.H5Fopen\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5fd.pyx\u001b[0m in \u001b[0;36mh5py.h5fd.H5FD_fileobj_read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'S3File' object has no attribute 'seek'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "with h5py.File(s3.open('s3://millionsongproject/A/A/A/TRAAAAV128F421A322.h5', 'rb'), 'r', lib_version='labtest') as f:\n",
    "    file_keys = list(f.keys())\n",
    "    print(file_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analysis', 'metadata', 'musicbrainz']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "with h5py.File(s3.open('s3://cosc502millionsong/millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5', 'rb'), 'r', lib_version='labtest') as f:\n",
    "    file_keys = list(f.keys())\n",
    "    print(file_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = ss.read.csv('s3://cosc502millionsong/df_test.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(_c0,StringType,true),StructField(_c1,StringType,true),StructField(_c2,StringType,true),StructField(_c3,StringType,true),StructField(_c4,StringType,true),StructField(_c5,StringType,true),StructField(_c6,StringType,true),StructField(_c7,StringType,true),StructField(_c8,StringType,true),StructField(_c9,StringType,true),StructField(_c10,StringType,true),StructField(_c11,StringType,true),StructField(_c12,StringType,true),StructField(_c13,StringType,true),StructField(_c14,StringType,true),StructField(_c15,StringType,true),StructField(_c16,StringType,true),StructField(_c17,StringType,true),StructField(_c18,StringType,true),StructField(_c19,StringType,true),StructField(_c20,StringType,true),StructField(_c21,StringType,true),StructField(_c22,StringType,true),StructField(_c23,StringType,true),StructField(_c24,StringType,true)))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+-------------------+---------------+-----+---------------+----------+----------------+-----------+--------------+-------------------+--------------+-------------------+---------------------+--------------------------+-----------------------+----------------+--------------+---------------+-----------------+------------+-------------+-------------------+-----------------+\n",
      "|                 _c0|        artist_terms|artist_terms_freq|artist_terms_weight|similar_artists|songs|bars_confidence|bars_start|beats_confidence|beats_start|analysis_songs|sections_confidence|sections_start|segments_confidence|segments_loudness_max|segments_loudness_max_time|segments_loudness_start|segments_pitches|segments_start|segments_timbre|tatums_confidence|tatums_start|artist_mbtags|artist_mbtags_count|musicbrainz_songs|\n",
      "+--------------------+--------------------+-----------------+-------------------+---------------+-----+---------------+----------+----------------+-----------+--------------+-------------------+--------------+-------------------+---------------------+--------------------------+-----------------------+----------------+--------------+---------------+-----------------+------------+-------------+-------------------+-----------------+\n",
      "|                   0|[b'salsa' b'cumbi...|             null|               null|           null| null|           null|      null|            null|       null|          null|               null|          null|               null|                 null|                      null|                   null|            null|          null|           null|             null|        null|         null|               null|             null|\n",
      "| b'tropical' b'in...|[1.         0.942...|             null|               null|           null| null|           null|      null|            null|       null|          null|               null|          null|               null|                 null|                      null|                   null|            null|          null|           null|             null|        null|         null|               null|             null|\n",
      "+--------------------+--------------------+-----------------+-------------------+---------------+-----+---------------+----------+----------------+-----------+--------------+-------------------+--------------+-------------------+---------------------+--------------------------+-----------------------+----------------+--------------+---------------+-----------------+------------+-------------+-------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_file.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=test_file.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', artist_terms=\"[b'salsa' b'cumbia' b'tejano' b'ranchera' b'latin pop' b'latin'\", artist_terms_freq=None, artist_terms_weight=None, similar_artists=None, songs=None, bars_confidence=None, bars_start=None, beats_confidence=None, beats_start=None, analysis_songs=None, sections_confidence=None, sections_start=None, segments_confidence=None, segments_loudness_max=None, segments_loudness_max_time=None, segments_loudness_start=None, segments_pitches=None, segments_start=None, segments_timbre=None, tatums_confidence=None, tatums_start=None, artist_mbtags=None, artist_mbtags_count=None, musicbrainz_songs=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
